{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os; os.chdir('..')\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from utils import *\n",
    "from boring_utils.utils import init_graph, set_seed, get_device, cprint, tprint\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Math Trick of Self-Attention\n",
    "\n",
    "At current time stemp, the current token can only communicate with the past."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 2])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B, T, C = 4, 8, 2  # batch size, time steps, channels\n",
    "x = torch.rand(B, T, C)\n",
    "x.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version 1: direct implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "xbow = torch.zeros((B, T, C))  # bag of words\n",
    "\n",
    "for b in range(B):\n",
    "    for t in range(T):\n",
    "        xprev = x[b, :t+1]  # (t, C)\n",
    "        xbow[b, t] = torch.mean(xprev, dim=0)  # (C,) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8823, 0.9150],\n",
       "        [0.3829, 0.9593],\n",
       "        [0.3904, 0.6009],\n",
       "        [0.2566, 0.7936],\n",
       "        [0.9408, 0.1332],\n",
       "        [0.9346, 0.5936],\n",
       "        [0.8694, 0.5677],\n",
       "        [0.7411, 0.4294]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8823, 0.9150],\n",
       "        [0.6326, 0.9372],\n",
       "        [0.5519, 0.8251],\n",
       "        [0.4780, 0.8172],\n",
       "        [0.5706, 0.6804],\n",
       "        [0.6313, 0.6659],\n",
       "        [0.6653, 0.6519],\n",
       "        [0.6748, 0.6241]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# xbow[0, a] is the previous average of x[0, :a+1]\n",
    "# (0.8823 + 0.3829) / 2 = xbow[0, 1][0]\n",
    "# (0.8823 + 0.3829 + 0.6706) / 3 = xbow[0, 2][0]\n",
    "# (0.8823 + 0.3829 + 0.6706 + 0.1948) / 4 = xbow[0, 3][0]\n",
    "xbow[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 3\n",
    "x[0, :a+1].sum(dim=0) / (a + 1) == xbow[0, a]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version 2: `torch.tril`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "==========\n",
      "tensor([[0., 1.],\n",
      "        [3., 0.],\n",
      "        [1., 1.]])\n",
      "==========\n",
      "tensor([[4., 2.],\n",
      "        [4., 2.],\n",
      "        [4., 2.]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(3, 3)\n",
    "b = torch.randint(0, 10, (3, 2)).float()\n",
    "c = a @ b\n",
    "\n",
    "print(a)\n",
    "print('=' * 10)\n",
    "print(b)\n",
    "print('=' * 10)\n",
    "print(c)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a clever way to implement xbow!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 1., 1.]])\n",
      "==========\n",
      "tensor([[7., 9.],\n",
      "        [4., 3.],\n",
      "        [8., 9.]])\n",
      "==========\n",
      "tensor([[ 7.,  9.],\n",
      "        [11., 12.],\n",
      "        [19., 21.]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tril(torch.ones(3, 3))\n",
    "b = torch.randint(0, 10, (3, 2)).float()\n",
    "c = a @ b\n",
    "\n",
    "print(a)\n",
    "print('=' * 10)\n",
    "print(b)\n",
    "print('=' * 10)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333]])\n",
      "==========\n",
      "tensor([[3., 7.],\n",
      "        [8., 1.],\n",
      "        [4., 1.]])\n",
      "==========\n",
      "tensor([[3.0000, 7.0000],\n",
      "        [5.5000, 4.0000],\n",
      "        [5.0000, 3.0000]])\n"
     ]
    }
   ],
   "source": [
    "# let's make row sum of `a` == 1\n",
    "\n",
    "a = torch.tril(torch.ones(3, 3))\n",
    "a = a / a.sum(dim=1, keepdim=True)\n",
    "b = torch.randint(0, 10, (3, 2)).float()\n",
    "c = a @ b\n",
    "\n",
    "print(a)\n",
    "print('=' * 10)\n",
    "print(b)\n",
    "print('=' * 10)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
       "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n",
       "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei = torch.tril(torch.ones(T, T))\n",
    "wei = wei / wei.sum(dim=1, keepdim=True)\n",
    "wei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xbow2 = wei @ x  # (B, T, T) @ (B, T, C) -> (B, T, C)\n",
    "\n",
    "# https://pytorch.org/docs/master/generated/torch.allclose.html#torch.allclose\n",
    "torch.allclose(xbow, xbow2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version 3: softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wei zero\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "==========\n",
      "wei masked\n",
      "tensor([[0., -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., 0., -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., 0., 0., -inf],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "==========\n"
     ]
    }
   ],
   "source": [
    "tril = torch.tril(torch.ones(T, T))\n",
    "# print('tril')\n",
    "# print(tril)\n",
    "# print('=' * 10)\n",
    "\n",
    "wei = torch.zeros((T, T))\n",
    "print('wei zero')\n",
    "print(wei)\n",
    "print('=' * 10)\n",
    "\n",
    "wei = wei.masked_fill(tril == 0, float(\"-inf\"))\n",
    "print('wei masked')\n",
    "print(wei)\n",
    "print('=' * 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wei softmax\n",
      "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
      "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n",
      "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei = F.softmax(wei, dim=-1)\n",
    "print('wei softmax')\n",
    "print(wei)\n",
    "\n",
    "xbow3 = wei @ x\n",
    "\n",
    "torch.allclose(xbow, xbow3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add self-attention\n",
    "\n",
    "- https://en.wikipedia.org/wiki/Attention_(machine_learning)\n",
    "- https://youtu.be/XhWdv7ghmQQ?t=306\n",
    "\n",
    "Note:\n",
    "- 01:11:38 note 1: attention as communication (DAG)\n",
    "- 01:12:46 note 2: attention has no notion of space, operates over sets\n",
    "- 01:13:40 note 3: there is no communication across batch dimension\n",
    "- 01:14:14 note 4: encoder blocks vs. decoder blocks\n",
    "- 01:15:39 note 5: attention vs. self-attention vs. cross-attention\n",
    "- 01:16:56 note 6: \"scaled\" self-attention. why divide by sqrt(head_size)\n",
    "\n",
    "increase channel to 32"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Not scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wei with key and query\n",
      "torch.Size([4, 8, 8])\n",
      "tensor([[-0.4756, -0.4828, -0.6072, -0.5931, -0.3054, -0.4079, -0.5894, -0.2347],\n",
      "        [-0.5114, -0.3956, -0.3761, -0.4249, -0.2592, -0.4078, -0.5005, -0.2828],\n",
      "        [-0.6586, -0.4215, -0.7198, -1.0157, -0.5398, -0.6188, -0.6399, -0.3925],\n",
      "        [-0.5370, -0.5140, -0.6704, -0.5307, -0.3981, -0.8240, -0.7268, -0.4975],\n",
      "        [-0.4817, -0.3755, -0.1522, -0.3692, -0.1520, -0.2697, -0.3343,  0.1223],\n",
      "        [-0.6250, -0.6073, -0.5404, -0.7432, -0.5004, -0.5817, -0.4660, -0.1888],\n",
      "        [-0.7550, -0.7983, -0.4413, -0.4475, -0.6948, -0.7523, -0.6267, -0.2331],\n",
      "        [-0.8731, -0.7870, -0.5414, -0.7434, -0.7863, -0.9081, -0.6232, -0.3012]],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "==========\n",
      "wei masked\n",
      "tensor([[-0.4756,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf],\n",
      "        [-0.5114, -0.3956,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf],\n",
      "        [-0.6586, -0.4215, -0.7198,    -inf,    -inf,    -inf,    -inf,    -inf],\n",
      "        [-0.5370, -0.5140, -0.6704, -0.5307,    -inf,    -inf,    -inf,    -inf],\n",
      "        [-0.4817, -0.3755, -0.1522, -0.3692, -0.1520,    -inf,    -inf,    -inf],\n",
      "        [-0.6250, -0.6073, -0.5404, -0.7432, -0.5004, -0.5817,    -inf,    -inf],\n",
      "        [-0.7550, -0.7983, -0.4413, -0.4475, -0.6948, -0.7523, -0.6267,    -inf],\n",
      "        [-0.8731, -0.7870, -0.5414, -0.7434, -0.7863, -0.9081, -0.6232, -0.3012]],\n",
      "       grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "B, T, C = 4, 8, 32  # batch size, time steps, channels\n",
    "x = torch.rand(B, T, C)\n",
    "# print(x.shape)\n",
    "\n",
    "tril = torch.tril(torch.ones(T, T))\n",
    "\n",
    "# single Head perform self-attention\n",
    "head_size = 16\n",
    "key = nn.Linear(C, head_size, bias=False)\n",
    "query = nn.Linear(C, head_size, bias=False)\n",
    "value = nn.Linear(C, head_size, bias=False)\n",
    "\n",
    "# The default initialization method for nn.Linear is Kaiming uniform\n",
    "# print(key.weight[0])\n",
    "\n",
    "# this will break the attention\n",
    "# nn.init.ones_(key.weight)\n",
    "# nn.init.ones_(query.weight)\n",
    "# nn.init.ones_(value.weight)\n",
    "\n",
    "k = key(x)  # (B, T, head_size) with x as input\n",
    "q = query(x)  # (B, T, head_size) with x as input\n",
    "\n",
    "# (B, T, head_size) @ (B, head_size, T) -> (B, T, T)\n",
    "wei = q @ k.transpose(-2, -1)  # (B, T, T)\n",
    "print('wei with key and query')\n",
    "print(wei.shape)\n",
    "print(wei[0])\n",
    "print('=' * 10)\n",
    "\n",
    "# disable this to make nodes communicate with each other fully\n",
    "wei = wei.masked_fill(tril == 0, float(\"-inf\"))\n",
    "print('wei masked')\n",
    "print(wei[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wei softmax\n",
      "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.4711, 0.5289, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.3117, 0.3951, 0.2932, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2561, 0.2621, 0.2241, 0.2577, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1663, 0.1850, 0.2313, 0.1861, 0.2313, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1620, 0.1649, 0.1763, 0.1440, 0.1835, 0.1692, 0.0000, 0.0000],\n",
      "        [0.1268, 0.1214, 0.1735, 0.1724, 0.1346, 0.1271, 0.1441, 0.0000],\n",
      "        [0.1027, 0.1120, 0.1432, 0.1170, 0.1121, 0.0992, 0.1319, 0.1820]],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "torch.Size([4, 8, 16])\n"
     ]
    }
   ],
   "source": [
    "wei = F.softmax(wei, dim=-1)\n",
    "print('wei softmax')\n",
    "print(wei[0])\n",
    "\n",
    "v = value(x)  # (B, T, head_size) with x as input\n",
    "out = wei @ v\n",
    "print(out.shape)  # (B, T, head_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.4711, 0.5289, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.3117, 0.3951, 0.2932, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2561, 0.2621, 0.2241, 0.2577, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1663, 0.1850, 0.2313, 0.1861, 0.2313, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1620, 0.1649, 0.1763, 0.1440, 0.1835, 0.1692, 0.0000, 0.0000],\n",
       "        [0.1268, 0.1214, 0.1735, 0.1724, 0.1346, 0.1271, 0.1441, 0.0000],\n",
       "        [0.1027, 0.1120, 0.1432, 0.1170, 0.1121, 0.0992, 0.1319, 0.1820]],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaled\n",
    "\n",
    "Why scaled is important: we need to feed this into softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0950)\n",
      "tensor([0.1925, 0.1426, 0.2351, 0.1426, 0.2872])\n",
      "tensor(6.0800)\n",
      "tensor([0.0326, 0.0030, 0.1615, 0.0030, 0.8000])\n"
     ]
    }
   ],
   "source": [
    "tmp = torch.tensor([0.1, -0.2, 0.3, -0.2, 0.5])\n",
    "\n",
    "print(tmp.var())\n",
    "print(torch.softmax(tmp, dim=-1))\n",
    "\n",
    "# this is more sharpen\n",
    "print((tmp * 8).var())\n",
    "print(torch.softmax(tmp * 8, dim=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0338)\n",
      "tensor(0.9856)\n",
      "tensor(16.7034)\n"
     ]
    }
   ],
   "source": [
    "k = torch.randn(B, T, head_size)\n",
    "q = torch.randn(B, T, head_size)\n",
    "wei = q @ k.transpose(-2, -1)\n",
    "\n",
    "print(k.var())\n",
    "print(q.var())\n",
    "print(wei.var())  # head_size is 16, so the variance is 16 times larger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0058)\n",
      "tensor(1.0581)\n",
      "tensor(1.1634)\n"
     ]
    }
   ],
   "source": [
    "k = torch.randn(B, T, head_size)\n",
    "q = torch.randn(B, T, head_size)\n",
    "wei = q @ k.transpose(-2, -1) * head_size ** -0.5\n",
    "\n",
    "print(k.var())\n",
    "print(q.var())\n",
    "print(wei.var())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
